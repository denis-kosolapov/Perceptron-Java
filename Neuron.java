package NeuralNetSimple;

public class Neuron {
    /*Модель двустороннего персептрона*/

    double[] enters; // входы
    double[] hidden; // скрытые нейроны
    double outer; //выходной нейрон, а для нейронов можно использовать массив

    /*Для связей используется двумерный массив. Первый индекс говорит от какого нейрона идет связь
    Второй индекс говорит к какому нейрону идет связь*/

    double[][] wEH; //веса между входными и скрытыми нейронам
    double[] wHO; //веса между скрытыми и выходными нейронами

    /*данные, которые подаются сети для обучения
     * Можно их скачать из файла*/

    double[][] patterns = {
            {0, 0}, {1, 0}, {0, 1}, {1, 1}
    };

    /*массив правил, значений которые хотим получать*/

    double[] answers = {0, 1, 1, 0};

    Neuron() {

        /*Можно подвязать количество входных нейронов по длине массива в патернах
        * Выбор количества внутренних нейронов - сложная задача. Это можно сделать имперически -
        * наращивать или уменьшать. Есть различные тактики*/
        enters = new double[patterns[0].length];
        /*попробуем сначала два, так как сеть достаточно простая*/
        hidden = new double[2];
        /*веса межу входными и скрыти нейронами
        *привязка по количеству нейронов от входного к скрытому*/
        wEH = new double[enters.length][hidden.length];
        /*от скрытого к выходному*/
        wHO = new double[hidden.length];

        /*Проверить результат работы программы*/
        initWeights();

        /*Запустить процедуру обучения на патернах*/
        study();

        /*Теперь нужно запустить проверку
        * Пробежаться по всем патернам и попробовать передавать их в качестве входных данных*/
        for (int p = 0; p < patterns.length; p++) {
            for (int i = 0; i < enters.length; i++)
                enters[i] = patterns[p][i];

            countOuter();
            System.out.println(outer); // вывести на консоль
        }

    }


    /*Инициализация весовых коэффициентов небольшими случайными значениями*/
    public void initWeights() {
        /*сначала перебираем массив входов*/
        for (int i = 0; i < enters.length; i++) {
            /*затем скрытые*/
            for (int j = 0; j < wEH.length; j++) {
                /*затем каждому присваиваем рандомное значение близкое к нулю
                * Math.random дает значение от 0 до 1, поэтому нужно или умножить его на 0,2
                * или прибавить 0,1 что при 0 даст значение 0,1, а при 1 0,2*/
                wEH[i][j] = Math.random() * 0.2 + 0.1; // получится от 0,1 до 0,2
            }
        }

        /*далее для скрытых и выходных*/
        for (int i = 0; i < wHO.length; i++)
            wHO[i] = Math.random() * 0.2 + 0.1;
    }

    /*Написание процедуры рассчета выхода*/

    public void countOuter() {
        /*сначала нужно рассчитать значения нейронов на скрытом слое
        * и на их основании посчитать значение выходноо нейрона*/

        /*считаем первый слой*/
        for (int i = 0; i < hidden.length; i++) {
            hidden[i] = 0; // обнулить скрытый нейрон
            for (int j = 0; j < enters.length; j++) {
                /*после обнуления в него остоянно добавляются значения с первого слоя*/
                /*i на входе, j на выходе*/
                hidden[i] += enters[j] * wEH[j][i];
            }
            /*затем нужно узнать - выше определенного порога сигнал или ниже*/

            /*если значение сигнала скрытого слоя больше 0,5, то нейрон объявляется 1
            * если нет, то 0*/
            if (hidden[i] > 0.5) hidden[i] = 1;
            else hidden[i] = 0;
        }

        /*теперь выходной слой*/
        outer = 0; //обнулить выходной нейрон

        /*затем перебрать нейроны скрытого слоя */
        for (int i = 0; i < hidden.length; i++) {
            /*между скрытым и выходным слоем вычислить значения*/
            outer += hidden[i] * wHO[i];
        }

        /*далее условия принятия решений*/
        if (outer > 0.5) outer = 1;
        else outer = 0;
    }

    /*Метод обучения персептрона
    * Нужно знать ошибку на выходе и ошибку скрытого слоя
    * Для ошибок скрытого слоя нужно завсти массив*/

    void study() {
        /*массив ошибок поолностью повторяет размерность массива нейронов на скрытом слое
        * Поэтому он привязывается к длине этого массива*/
        double[] err = new double[hidden.length];

        /*Глобальная ошибка вычисляется для всех обучающих примеров, для всех патернов */
        double gError = 0;

        /*Далее сама обучающая процедура длится до успешного результата*/
        do {

            /*Последовательно определяем все обучающие патерны
            * Для каждого из них рассчитываем выход, ошибку в сравнении с той
            * которую хотели получить и корректируем весовые коэффициенты исходя из этой ошибки*/

            /*Для каждой итерации цикла нужно обнулять глобальную ошику*/
            gError = 0;

            /*Данный цикл перебирает патерны*/
            for (int p = 0; p < patterns.length; p++) {
                /*цикл для перебора всех входных нейронв*/
                for (int i = 0; i < enters.length; i++)
                    /*копируем значение из входа i из патернов*/
                    enters[i] = patterns[p][i];

                /*Теперь нужно посчитать выходное значение*/
                countOuter();

                /*Теперь переменная для хранения локальной ошибки
                * которая равна разнице между идеальным значением answers, под номером p
                * минус значение которое получили на выходе на самом деле*/
                double lErr = answers[p] - outer; //заводим локальную ошибку

                /*Рассчет глобальной ошибки
                * Нужно суммировать ее по модулю
                * так как ошибка может быть как положительной, так и отрицательной*/
                gError += Math.abs(lErr);

                /*Подсчет ошибок обратного распространения*/
                for (int i = 0; i < hidden.length; i++)
                    err[i] = lErr * wHO[i]; // все ошибки на скрытом слое

                /*На основании ошибки корректируем весовые коэффициенты*/
                for (int i = 0; i < enters.length; i++) {
                    /*корректируем вес от скрытого слоя к выходному*/
                    for (int j = 0; j < hidden.length; j++) {
                        /*ошибка берется на скрытом слопе*/
                        wEH[i][j] += 0.1 * err[j] * enters[i];
                    }
                }

                /*теперь корректируем коэффициенты на выходном слое*/
                for (int i = 0; i < hidden.length; i++)
                    /*здесь берется локальная ошибка*/
                    wHO[i] += 0.1 * lErr * hidden[i];
            }
            /*признак обученности */
        } while (gError != 0);
    }
}
